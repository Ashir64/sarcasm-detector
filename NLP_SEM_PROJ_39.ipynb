{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mE8Df5IkE4Ud"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import pickle\n",
        "\n",
        "data = []\n",
        "for line in open(\"Sarcasm_Headlines_Dataset.json\", \"r\"):\n",
        "    data.append(json.loads(line))\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df = df[['headline', 'is_sarcastic']]\n",
        "df.rename(columns={'headline':'text','is_sarcastic':'label'}, inplace=True)\n",
        "\n",
        "def normalize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "    return text\n",
        "\n",
        "df['text_norm'] = df['text'].apply(normalize)\n",
        "\n",
        "# Marker feature\n",
        "markers = [\"oh great\",\"yeah right\",\"love that\",\"just what i needed\",\"sure\"]\n",
        "df['has_marker'] = df['text'].str.lower().apply(lambda t: int(any(m in t for m in markers)))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5952e149"
      },
      "source": [
        "X = df['text_norm']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test, df_train, df_test = train_test_split(\n",
        "    X, y, df, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "tfidf_word = TfidfVectorizer(max_features=5500, ngram_range=(1,2), stop_words='english')\n",
        "tfidf_char = TfidfVectorizer(analyzer='char', ngram_range=(3,5), max_features=3000)\n",
        "\n",
        "Xw_train = tfidf_word.fit_transform(X_train)\n",
        "Xw_test  = tfidf_word.transform(X_test)\n",
        "Xc_train = tfidf_char.fit_transform(X_train)\n",
        "Xc_test  = tfidf_char.transform(X_test)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_marker = np.array(df_train['has_marker']).reshape(-1,1)\n",
        "test_marker  = np.array(df_test['has_marker']).reshape(-1,1)\n",
        "\n",
        "X_train_final = hstack([Xw_train, Xc_train, csr_matrix(train_marker)])\n",
        "X_test_final  = hstack([Xw_test, Xc_test, csr_matrix(test_marker)])"
      ],
      "metadata": {
        "id": "aTxUe2w_taWm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(class_weight='balanced', max_iter=2000),\n",
        "    'LinearSVC': LinearSVC(class_weight='balanced', max_iter=2000),\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'BernoulliNB': BernoulliNB(),\n",
        "    'DecisionTree': DecisionTreeClassifier(),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=200),\n",
        "    'ExtraTrees': ExtraTreesClassifier(n_estimators=200),\n",
        "    'GradientBoosting': GradientBoostingClassifier(n_estimators=200),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=200),\n",
        "    'KNeighbors': KNeighborsClassifier(n_neighbors=5)\n",
        "}"
      ],
      "metadata": {
        "id": "fJ_xgwSrFZv3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    model.fit(X_train_final, y_train)\n",
        "    preds = model.predict(X_test_final)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "    print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
        "    results.append([name, acc, f1])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOGTaWbvzArH",
        "outputId": "62443201-9bab-47f7-b9cd-cc8a045118e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LogisticRegression:\n",
            "Accuracy: 0.8469, F1: 0.8294\n",
            "\n",
            "LinearSVC:\n",
            "Accuracy: 0.8413, F1: 0.8218\n",
            "\n",
            "MultinomialNB:\n",
            "Accuracy: 0.8310, F1: 0.8053\n",
            "\n",
            "BernoulliNB:\n",
            "Accuracy: 0.7965, F1: 0.7782\n",
            "\n",
            "DecisionTree:\n",
            "Accuracy: 0.6997, F1: 0.6594\n",
            "\n",
            "RandomForest:\n",
            "Accuracy: 0.8016, F1: 0.7692\n",
            "\n",
            "ExtraTrees:\n",
            "Accuracy: 0.8149, F1: 0.7843\n",
            "\n",
            "GradientBoosting:\n",
            "Accuracy: 0.7917, F1: 0.7682\n",
            "\n",
            "AdaBoost:\n",
            "Accuracy: 0.7486, F1: 0.7165\n",
            "\n",
            "KNeighbors:\n",
            "Accuracy: 0.6853, F1: 0.5393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results, columns=['Model','Accuracy','F1'])\n",
        "results_df = results_df.sort_values(by='F1', ascending=False).reset_index(drop=True)\n",
        "print(\"\\nSummary of 10 Models:\\n\", results_df)"
      ],
      "metadata": {
        "id": "xgja3tNezDaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbe4baa-df09-44e0-ab89-f76e7cf7b2c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary of 10 Models:\n",
            "                 Model  Accuracy        F1\n",
            "0  LogisticRegression  0.846874  0.829441\n",
            "1           LinearSVC  0.841258  0.821849\n",
            "2       MultinomialNB  0.830962  0.805262\n",
            "3          ExtraTrees  0.814863  0.784297\n",
            "4         BernoulliNB  0.796518  0.778209\n",
            "5        RandomForest  0.801572  0.769164\n",
            "6    GradientBoosting  0.791651  0.768173\n",
            "7            AdaBoost  0.748596  0.716487\n",
            "8        DecisionTree  0.699738  0.659448\n",
            "9          KNeighbors  0.685324  0.539326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   # Find best model\n",
        "best_idx = results_df['F1'].idxmax()\n",
        "best_model_name = results_df.loc[best_idx, 'Model']\n",
        "best_model_f1 = results_df.loc[best_idx, 'F1']\n",
        "best_model_acc = results_df.loc[best_idx, 'Accuracy']\n",
        "\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "print(f\"Accuracy: {best_model_acc:.4f}\")\n",
        "print(f\"F1 Score: {best_model_f1:.4f}\")\n",
        "\n",
        "# best model\n",
        "best_model_object = models[best_model_name]\n",
        "\n",
        "import pickle\n",
        "with open('best_sarcasm_model.pkl','wb') as f:\n",
        "    pickle.dump(best_model_object, f)\n",
        "\n",
        "# Save  vectorizers used\n",
        "with open('tfidf_word.pkl','wb') as f:\n",
        "    pickle.dump(tfidf_word, f)\n",
        "\n",
        "with open('tfidf_char.pkl','wb') as f:\n",
        "    pickle.dump(tfidf_char, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5VepxLxztcl",
        "outputId": "da499a74-3567-4c7a-d4d0-2839f51b8a09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: LogisticRegression\n",
            "Accuracy: 0.8469\n",
            "F1 Score: 0.8294\n"
          ]
        }
      ]
    }
  ]
}